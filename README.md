# 🎙️ AI Interview Simulator

[![Hugging Face Space](https://img.shields.io/badge/🤗%20Hugging%20Face-Space-blue)](https://huggingface.co/spaces/yourusername/ai-interview-simulator)

Practice your interview skills and get real-time, personalized feedback powered by AI!

## 🚀 Features

*   **🎤 Voice Interaction:** Answer interview questions using your microphone.
*   **📝 Real-time Transcription:** Get an instant text transcription of your answer using OpenAI's Whisper.
*   **🤖 AI-Powered Feedback:** Receive detailed, constructive feedback on your content, clarity, structure, and suggestions for improvement, generated by Google's Gemma 2B IT model.
*   **💼 Role-Specific Questions:** Choose from a wide variety of job roles (React, JavaScript, Java, Python, SQL, Data Science, DevOps, and many more) to get relevant interview questions.
*   **🌐 Web-based:** Access the simulator directly in your browser, no installation required.

## 🎯 How to Use

1.  **Select a Job Role:** Choose a role from the dropdown menu (e.g., React Developer, Data Scientist).
2.  **Select a Question:** Pick a specific interview question related to the chosen role.
3.  **Record Your Answer:**
    *   Click the red **'Record'** button.
    *   Speak your answer clearly.
    *   Click the **'Stop'** button when finished.
4.  **Get Feedback:**
    *   Click the **'🚀 Submit & Get Feedback'** button immediately.
    *   Wait for the AI to process your response.
5.  **Review Results:**
    *   See the **transcription** of your answer.
    *   Read the detailed **AI-generated feedback**.

**💡 Tip:** If you see 'No microphone found', please check your browser's address bar for the microphone permission icon and allow access. You might need to reload the page after granting permission.

## 🛠️ Technical Stack

*   **Frontend/UI:** [Gradio](https://gradio.app/)
*   **Speech-to-Text:** [OpenAI Whisper (Tiny model)](https://github.com/openai/whisper)
*   **LLM (Feedback Engine):** [Google Gemma 2B IT](https://huggingface.co/google/gemma-2b-it)
*   **Deployment:** [Hugging Face Spaces (Docker)](https://huggingface.co/docs/hub/spaces)

## 📦 Installation (For Local Development/Running)

While designed for Hugging Face Spaces, you can run it locally.

<details>
<summary>Click to expand local setup instructions</summary>

1.  **Clone the Repository**
    ```bash
    git clone https://huggingface.co/spaces/yourusername/ai-interview-simulator
    cd ai-interview-simulator
    ```
2.  **Set Up Environment**
    *   It's recommended to use a virtual environment:
    ```bash
    python -m venv venv
    source venv/bin/activate # On Windows: venv\Scripts\activate
    ```
3.  **Install Dependencies**
    ```bash
    pip install -r requirements.txt
    ```
    *(Note: Ensure you have `ffmpeg` installed on your system for Whisper.)*
4.  **Set Environment Variables**
    *   Create a `.env` file or set environment variables:
    ```bash
    HF_TOKEN=your_hugging_face_token_with_access_to_gemma
    WHISPER_MODEL=tiny # Optional: tiny, base, small (larger models are more accurate but slower)
    ```
5.  **Run the Application**
    ```bash
    python app.py
    ```
6.  **Access the App**
    *   Open your browser and go to `http://localhost:7860`.

</details>

## 🤝 Contributing

Contributions are welcome! Feel free to open issues or submit pull requests on Hugging Face.

## 📄 License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## 🙏 Acknowledgments

*   [OpenAI](https://openai.com/) for the Whisper speech recognition model.
*   [Google](https://ai.google/) for the Gemma language model.
*   [Hugging Face](https://huggingface.co/) for providing the platform and libraries.
